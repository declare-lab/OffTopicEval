2025-09-28 19:23:05.202157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1759087385.223381 2198358 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1759087385.230262 2198358 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1759087385.250088 2198358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087385.250127 2198358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087385.250132 2198358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087385.250136 2198358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
INFO 09-28 19:23:09 [__init__.py:216] Automatically detected platform cuda.
[1;36m(APIServer pid=2198358)[0;0m INFO 09-28 19:23:11 [api_server.py:1896] vLLM API server version 0.10.2
[1;36m(APIServer pid=2198358)[0;0m INFO 09-28 19:23:11 [utils.py:328] non-default args: {'model': 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'tokenizer_mode': 'mistral'}
[1;36m(APIServer pid=2198358)[0;0m INFO 09-28 19:23:26 [__init__.py:742] Resolved architecture: Mistral3ForConditionalGeneration
[1;36m(APIServer pid=2198358)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=2198358)[0;0m INFO 09-28 19:23:26 [__init__.py:1815] Using max model len 131072
[1;36m(APIServer pid=2198358)[0;0m INFO 09-28 19:23:26 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=2198358)[0;0m The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[1;36m(APIServer pid=2198358)[0;0m /home/ubuntu/.local/lib/python3.10/site-packages/mistral_common/protocol/instruct/messages.py:74: FutureWarning: ImageChunk has moved to 'mistral_common.protocol.instruct.chunk'. It will be removed from 'mistral_common.protocol.instruct.messages' in 1.10.0.
[1;36m(APIServer pid=2198358)[0;0m   warnings.warn(msg, FutureWarning)
2025-09-28 19:23:36.563858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1759087416.582971 2198729 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1759087416.589236 2198729 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1759087416.607613 2198729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087416.607652 2198729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087416.607658 2198729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759087416.607764 2198729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
INFO 09-28 19:23:40 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=2198729)[0;0m INFO 09-28 19:23:42 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2198729)[0;0m INFO 09-28 19:23:42 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='mistralai/Mistral-Small-3.2-24B-Instruct-2506', speculative_config=None, tokenizer='mistralai/Mistral-Small-3.2-24B-Instruct-2506', skip_tokenizer_init=False, tokenizer_mode=mistral, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-Small-3.2-24B-Instruct-2506, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[W928 19:23:45.056454587 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2198729)[0;0m INFO 09-28 19:23:45 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2198729)[0;0m /home/ubuntu/.local/lib/python3.10/site-packages/mistral_common/protocol/instruct/messages.py:74: FutureWarning: ImageChunk has moved to 'mistral_common.protocol.instruct.chunk'. It will be removed from 'mistral_common.protocol.instruct.messages' in 1.10.0.
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   warnings.warn(msg, FutureWarning)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m WARNING 09-28 19:23:47 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/image_processing_base.py", line 354, in get_image_processor_dict
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     resolved_image_processor_file = resolved_image_processor_files[0]
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] IndexError: list index out of range
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] 
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] During handling of the above exception, another exception occurred:
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] 
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 709, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 505, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 82, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self.collective_rpc("init_device")
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     answer = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/utils/__init__.py", line 3060, in run_method
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 611, in init_device
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 201, in init_device
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self.model_runner: GPUModelRunner = GPUModelRunner(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 383, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     self.mm_budget = MultiModalBudget(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/utils.py", line 47, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     max_tokens_by_modality = mm_registry \
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 168, in get_max_tokens_per_item_by_nonzero_modality
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     max_tokens_per_item = self.get_max_tokens_per_item_by_modality(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 144, in get_max_tokens_per_item_by_modality
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return profiler.get_mm_max_contiguous_tokens(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 311, in get_mm_max_contiguous_tokens
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return self._get_mm_max_tokens(seq_len,
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 291, in _get_mm_max_tokens
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     mm_inputs = self._get_dummy_mm_inputs(seq_len, mm_counts)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 170, in _get_dummy_mm_inputs
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     processor_inputs = factory.get_dummy_processor_inputs(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 92, in get_dummy_processor_inputs
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     dummy_text = self.get_dummy_text(mm_counts)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/model_executor/models/mistral3.py", line 203, in get_dummy_text
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     processor = self.info.get_hf_processor()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/model_executor/models/mistral3.py", line 229, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return self.ctx.get_hf_processor(PixtralProcessor, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/inputs/registry.py", line 138, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return super().get_hf_processor(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/inputs/registry.py", line 101, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return cached_processor_from_config(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 143, in cached_processor_from_config
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     return cached_get_processor(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 102, in get_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     processor = processor_cls.from_pretrained(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 1331, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 1390, in _get_arguments_from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 491, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     raise initial_exception
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 473, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/image_processing_base.py", line 361, in get_image_processor_dict
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718]     raise OSError(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m ERROR 09-28 19:23:47 [core.py:718] OSError: Can't load image processor for 'mistralai/Mistral-Small-3.2-24B-Instruct-2506'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'mistralai/Mistral-Small-3.2-24B-Instruct-2506' is the correct path to a directory containing a preprocessor_config.json file
[1;36m(EngineCore_DP0 pid=2198729)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2198729)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/image_processing_base.py", line 354, in get_image_processor_dict
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     resolved_image_processor_file = resolved_image_processor_files[0]
[1;36m(EngineCore_DP0 pid=2198729)[0;0m IndexError: list index out of range
[1;36m(EngineCore_DP0 pid=2198729)[0;0m 
[1;36m(EngineCore_DP0 pid=2198729)[0;0m During handling of the above exception, another exception occurred:
[1;36m(EngineCore_DP0 pid=2198729)[0;0m 
[1;36m(EngineCore_DP0 pid=2198729)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 722, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 709, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 505, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core.py", line 82, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.collective_rpc("init_device")
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     answer = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/utils/__init__.py", line 3060, in run_method
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 611, in init_device
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 201, in init_device
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.model_runner: GPUModelRunner = GPUModelRunner(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_model_runner.py", line 383, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.mm_budget = MultiModalBudget(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/utils.py", line 47, in __init__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     max_tokens_by_modality = mm_registry \
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 168, in get_max_tokens_per_item_by_nonzero_modality
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     max_tokens_per_item = self.get_max_tokens_per_item_by_modality(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/registry.py", line 144, in get_max_tokens_per_item_by_modality
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return profiler.get_mm_max_contiguous_tokens(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 311, in get_mm_max_contiguous_tokens
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return self._get_mm_max_tokens(seq_len,
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 291, in _get_mm_max_tokens
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     mm_inputs = self._get_dummy_mm_inputs(seq_len, mm_counts)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 170, in _get_dummy_mm_inputs
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     processor_inputs = factory.get_dummy_processor_inputs(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/multimodal/profiling.py", line 92, in get_dummy_processor_inputs
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     dummy_text = self.get_dummy_text(mm_counts)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/model_executor/models/mistral3.py", line 203, in get_dummy_text
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     processor = self.info.get_hf_processor()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/model_executor/models/mistral3.py", line 229, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return self.ctx.get_hf_processor(PixtralProcessor, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/inputs/registry.py", line 138, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return super().get_hf_processor(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/inputs/registry.py", line 101, in get_hf_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return cached_processor_from_config(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 143, in cached_processor_from_config
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     return cached_get_processor(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/transformers_utils/processor.py", line 102, in get_processor
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     processor = processor_cls.from_pretrained(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 1331, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/processing_utils.py", line 1390, in _get_arguments_from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 491, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     raise initial_exception
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 473, in from_pretrained
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/image_processing_base.py", line 361, in get_image_processor_dict
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     raise OSError(
[1;36m(EngineCore_DP0 pid=2198729)[0;0m OSError: Can't load image processor for 'mistralai/Mistral-Small-3.2-24B-Instruct-2506'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'mistralai/Mistral-Small-3.2-24B-Instruct-2506' is the correct path to a directory containing a preprocessor_config.json file
[1;36m(EngineCore_DP0 pid=2198729)[0;0m Exception ignored in: <function ExecutorBase.__del__ at 0x7ab7fe3b5fc0>
[1;36m(EngineCore_DP0 pid=2198729)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 237, in __del__
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.shutdown()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 76, in shutdown
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     worker.shutdown()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/worker/worker_base.py", line 528, in shutdown
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.worker.shutdown()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/worker/gpu_worker.py", line 675, in shutdown
[1;36m(EngineCore_DP0 pid=2198729)[0;0m     self.model_runner.ensure_kv_transfer_shutdown()
[1;36m(EngineCore_DP0 pid=2198729)[0;0m AttributeError: 'NoneType' object has no attribute 'ensure_kv_transfer_shutdown'
[rank0]:[W928 19:23:48.396262541 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=2198358)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=2198358)[0;0m   File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
[1;36m(APIServer pid=2198358)[0;0m     return _run_code(code, main_globals, None,
[1;36m(APIServer pid=2198358)[0;0m   File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
[1;36m(APIServer pid=2198358)[0;0m     exec(code, run_globals)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 2011, in <module>
[1;36m(APIServer pid=2198358)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/uvloop/__init__.py", line 82, in run
[1;36m(APIServer pid=2198358)[0;0m     return loop.run_until_complete(wrapper())
[1;36m(APIServer pid=2198358)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=2198358)[0;0m     return await main
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1941, in run_server
[1;36m(APIServer pid=2198358)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1961, in run_server_worker
[1;36m(APIServer pid=2198358)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=2198358)[0;0m   File "/usr/lib/python3.10/contextlib.py", line 199, in __aenter__
[1;36m(APIServer pid=2198358)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 179, in build_async_engine_client
[1;36m(APIServer pid=2198358)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=2198358)[0;0m   File "/usr/lib/python3.10/contextlib.py", line 199, in __aenter__
[1;36m(APIServer pid=2198358)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 221, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=2198358)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/utils/__init__.py", line 1589, in inner
[1;36m(APIServer pid=2198358)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 212, in from_vllm_config
[1;36m(APIServer pid=2198358)[0;0m     return cls(
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/async_llm.py", line 136, in __init__
[1;36m(APIServer pid=2198358)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 102, in make_async_mp_client
[1;36m(APIServer pid=2198358)[0;0m     return AsyncMPClient(*client_args)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 769, in __init__
[1;36m(APIServer pid=2198358)[0;0m     super().__init__(
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/core_client.py", line 448, in __init__
[1;36m(APIServer pid=2198358)[0;0m     with launch_core_engines(vllm_config, executor_class,
[1;36m(APIServer pid=2198358)[0;0m   File "/usr/lib/python3.10/contextlib.py", line 142, in __exit__
[1;36m(APIServer pid=2198358)[0;0m     next(self.gen)
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 729, in launch_core_engines
[1;36m(APIServer pid=2198358)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=2198358)[0;0m   File "/home/ubuntu/.local/lib/python3.10/site-packages/vllm/v1/engine/utils.py", line 782, in wait_for_engine_startup
[1;36m(APIServer pid=2198358)[0;0m     raise RuntimeError("Engine core initialization failed. "
[1;36m(APIServer pid=2198358)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
